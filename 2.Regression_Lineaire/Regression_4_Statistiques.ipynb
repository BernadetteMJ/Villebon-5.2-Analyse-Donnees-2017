{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons explorer un peu le résultat de notre regression, et en profiter pour entrer un peu plus dans le monde des statistiques.\n",
    "\n",
    "Nous allons rappeler quelques concepts fondamentaux, et les utiliser pour analyser les coefficients que nous calculons avec la descente par gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage\n",
    "\n",
    "Rappelons tout d'abord que le fait que nous utilisions des données synthétiques pour nos analyses nous donnent un avantage que nous n'avons pas dans la vraie vie, i.e. connaître les vraies valeurs des coefficients.\n",
    "\n",
    "Les données auxquelles on a accès sont généralement un échantillon d'une population plus large, et nous faisons l'hypothèse qu'ils peuvent être expliqué par un modèle linéaire.\n",
    "\n",
    "Le but de l'inférence statistique est de nous permettre de quantifier au mieux notre connaissance sur les paramètres sous-jacents, à partir des données observées.\n",
    "\n",
    "Plusieurs échantillons peuvent être extraits d'une même population. Les statistiques calculées sur les différents échantillons peuvent varier, mais on s'attend en moyenne à ce qu'elles convergent vers les valeurs vraies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_index(x, size):\n",
    "    \"\"\"sample random elements and return array index with length defined by size\n",
    "    \n",
    "        Args:\n",
    "            x (numpy.array) : vector to sample from\n",
    "        Returns:\n",
    "            numpy.array with length defined by size\n",
    "    \"\"\"\n",
    "    index = np.arange(x.size)\n",
    "    np.random.shuffle(index)\n",
    "    return index[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le code suivant, nous allons simplement générer une liste d'entier, et calculer la moyenne sur quelques échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "print \"true mean\", x.mean()\n",
    "for i in range(10):\n",
    "    print x[sample_index(x, 10)].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intéressons-nous maintenant à la variation par rapport à cette valeur centrale.\n",
    "\n",
    "### Théorème central limite :\n",
    "Soit X une grandeur avec une moyenne $\\mu$ et une variance finie $\\sigma^2$, alors lorsque la taille de l'échantillon N tend vers $+\\infty$, La distribution de X tend vers une  distribution gaussienne centrée autour de la valeur réelle, et dont l'erreur évolue en $1/\\sqrt N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Exemple distribution binomiale\n",
    "coin = [1, 0]\n",
    "\n",
    "N = 10000.\n",
    "binomial = np.random.choice(coin, N)\n",
    "print \"La probablité d'avoir un pile ou un face : \", binomial.mean()\n",
    "# Le fait d'avoir mis 0 et 1 simplifie le calcul de la probabilité.\n",
    "# Sinon il aurait fallu compter le nombre de pile et diviser par le total.\n",
    "\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    samples.append(binomial[sample_index(binomial, 100)].mean())\n",
    "\n",
    "plt.hist(samples, bins=50, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise généralement la variable Z pour résumer cette propriété\n",
    "\n",
    "$$Z = \\frac{\\bar X-\\mu}{\\sigma / \\sqrt N} \\rightarrow N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervalles de confiances\n",
    "\n",
    "On peut alors en déduire un encadrement des valeurs qui nous intéressent, avec une certaine \"confiance\". Par exemple, on sait que dans 95% des cas, la valeur tombera dans l'intervalle suivant :\n",
    "\n",
    "$$\\mu - 1.96 \\sigma/\\sqrt n < \\bar X < \\mu + 1.96 \\sigma/\\sqrt n$$\n",
    "\n",
    "Par conséquent, on a également (simple réecriture de l'équation précédente):\n",
    "\n",
    "$$\\bar X - 1.96 \\sigma/\\sqrt n < \\mu < \\bar X + 1.96 \\sigma /\\sqrt n$$\n",
    "\n",
    "et qu'on appelle l'intervalle de confiance, avec un niveau de confiance de 95%. \n",
    "**Cette intervalle contient la vraie valeur dans 95% des cas.**\n",
    "\n",
    "Vous pouvez voir ici une illustration : http://rpsychologist.com/d3/CI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution de Student\n",
    "\n",
    "Sauf que $\\sigma$ n'est généralement pas connu à priori !\n",
    "\n",
    "Un estimateur non-biaisé de $\\sigma^2$ est $s^2 = \\frac{1}{N-1}\\sum_i (x_i - \\bar X)^2$, i.e. en moyenne, $s^2$ tend vers $\\sigma^2$ dans la limite des grands nombres.\n",
    "\n",
    "$\\frac{s}{\\sqrt N}$ est communément appelée **erreur standard.**\n",
    " \n",
    "Dans ce cas, les encadrements précédents ne sont plus vrais. Cette nouvelle inconnue introduit de l'incertitude supplémentaire, qui va élargir les intervalles. Nous avons donc une nouvelle distibution, dite de Student ou t.\n",
    "\n",
    "$$ t = \\frac{\\bar X-\\mu}{s / \\sqrt N}$$\n",
    "\n",
    "L'intervalle est modifié de la façon suivante\n",
    "$$\\bar X - t^* \\frac{s}{\\sqrt N} < \\mu < \\bar X + t^* \\frac{s}{\\sqrt N}$$\n",
    "\n",
    "Bien évidemment, le théorème central limite est toujours valide, et lorsque N est grand, la distribution tend vers une loi normale.\n",
    "\n",
    "Le nombre $t^*$ doit être calculé et varie en fonction de la taille de l'échantillon. On parle de degrés de liberté. \n",
    "\n",
    "Degrés de liberté = Nombre de points - nombre de relations entre les points\n",
    "\n",
    "Ici on compte la moyenne comme une relation entre les points, et par conséquent, on considère qu'il y **N-1** degrés de liberté."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions statistiques avec scipy\n",
    "\n",
    "Jusqu'à présent nous avons utilisé le module random de numpy pour générer des points aléatoires qui suivent une distribution normale.\n",
    "\n",
    "Nous allons maintenant utiliser le paquet statistique de scipy pour pouvoir aller plus loin avec les distributions, comme notamment calculer les \n",
    "\n",
    "Le sous-module stats de scipy donne accès à différentes distributions statistiques discrètes et continues.\n",
    "\n",
    "Nous allons comparer la distribution de probabilité gaussienne et la distribution t.\n",
    "\n",
    "On utilise la méthode pdf : probability density function, ou densité de probabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10,10, 100)\n",
    "plt.plot(x, norm.pdf(x), 'r-', lw=1, alpha=0.6, label='norm pdf')\n",
    "plt.plot(x, t.pdf(x,df=1), 'g-', lw=1, alpha=0.6, label='student pdf df=1')\n",
    "plt.plot(x, t.pdf(x,df=100), 'b+', lw=1, alpha=0.6, label='student pdf df=100')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une deuxième méthode utile est la cdf, ou cumulated density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x, norm.cdf(x), 'r-', lw=1, alpha=0.6, label='norm cdf')\n",
    "plt.hlines(0.5, x.min(), x.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction inverse, la percent point function est celle qui nous intéresse pour calculer les intervalles de confiances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.linspace(0,1)\n",
    "plt.plot(p, norm.ppf(p), 'r-', lw=1, alpha=0.6, label='norm ppf')\n",
    "plt.vlines(0.5, -3, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, nous pouvons retrouver la valeur z correspondant à un intervalle pour 95%. On cherche donc les points (1-0.95)/2 et 1-(1-0.95)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print norm.ppf(0.025)\n",
    "print norm.ppf(1-0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve bien les valeurs de -1.96 et 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons faire la même chose avec la distribution t. Mais en n'oubliant pas de préciser les degrés de liberté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [1,5,10,100,1000]:\n",
    "    print t.ppf(0.025, df=df), t.ppf(1-0.025, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de la régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('POO/') #Nous pouvons spécifier à python où aller chercher nos modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from regression.linear_regression import Linear\n",
    "from simu_data import generate_data\n",
    "\n",
    "x,y = generate_data(100, params=(10, -2), var = 5)\n",
    "l = Linear(x,y)\n",
    "l.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = sample_index(x,10)\n",
    "l.x, l.y = x[index], y[index]\n",
    "l.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = Linear(x,y)\n",
    "params_gd = l.fit(optimisation=\"descente_gradient\")\n",
    "print params_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = sample_index(x,10)\n",
    "l = Linear(x[idx],y[idx])\n",
    "params_gd = l.fit(optimisation=\"descente_gradient\")\n",
    "params_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_params = []\n",
    "\n",
    "for i in range(100):\n",
    "    idx = sample_index(x,10)\n",
    "    l = Linear(x[idx],y[idx])\n",
    "    sampled_params.append(l.fit(optimisation=\"descente_gradient\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_params = np.array(sampled_params)\n",
    "plt.hist(sampled_params[:,0], bins=50)\n",
    "plt.figure()\n",
    "plt.hist(sampled_params[:,1], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principe des tests statistiques\n",
    "\n",
    "Nous formulons une hypothèse initiale $H_0$ que nous considérons comme vraie\n",
    "\n",
    "$H_0$ : Pas de relations entre X et Y et $\\theta_1 = 0$\n",
    "\n",
    "$H a$ : Il y a une relation une X et Y\n",
    "\n",
    "Nous vérifions la probabilité d'occurence de la valeur de notre paramètres $\\theta_1$, qui encode la relation de dépendance linéaire, étant donné l'hypothèse nulle.\n",
    "\n",
    "Cette valeur est la p-value. Si elle est supérieure à une valeur critique, alors on ne peut pas rejeter l'hypothèse nulle. Cette valeur critique dépend du domaine.\n",
    "\n",
    "Il est courant de prendre p = 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A combien sommes-nous de l'hypothèse nulle ?\n",
    "$$t = \\frac{\\hat \\theta_1 - 0}{s/\\sqrt N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommes-nous suffisamment loin pour rejeter l'hypothèse nulle ?\n",
    "$$P(t_{\\alpha/2}<\\frac{\\hat \\theta_1}{s/\\sqrt N}<t_{1-\\alpha/2})$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
