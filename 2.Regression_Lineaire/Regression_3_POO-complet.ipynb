{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans ce cours synthétiser ce que nous avons vu jusqu'à présent. Pour cela, nous allons construire une classe intégré dans un module qui permet de faire de la régression linéaire, que vous pouvez réutiliser et/ou partager de façon transparente.\n",
    "\n",
    "Avant toute chose, **créez un dossier POO** dans le répertoire de votre choix.\n",
    "\n",
    "<h2> 1ère étape : créer un module permettant de générer nos données. </h2>\n",
    "\n",
    "$\\Rightarrow$ créez le fichier **`simu_data.py`** en y incluant la fonction `linear` que nous avons vue et utilisée dans les cours précédents. Dans ce fichier, pensez à également définir la fonction `main()`. </br>\n",
    "Remarque : pour plus de clareté pour le code, dorénavent nous appelons cette fonction **`generate_data`** :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(N=100, params=(0,1), var=1):\n",
    "    \"\"\" Fonction simulant les donnees : on genere une distribution de points au\n",
    "        voisinage d'une droite avec la fonction lineaire : f(x)=a*x+b+N(0,1)\n",
    "        (cf la fonction linear de Regression_1.ipynb)\n",
    "        \n",
    "        N      : nombre de points pour generer le vecteur x\n",
    "        params : parametres de la fonction : b=params[0] et a=params[1]\n",
    "        var    : facteur faisant varier la variance de la fonction normale N(0,1)\n",
    "    \"\"\"\n",
    "    x = 10*np.random.random(N)\n",
    "    y = params[0] + params[1]*x + var*np.random.normal(size=len(x))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la fonction `main()` à la fin de notre fichier `sime_data.py`, on peut décider de sauvegarder les points de données générés dans un fichier texte au format csv, pour pouvoir les réutiliser plus tard sans avoir à les générer à chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partie du script qui sera execute seulement lorsqu'on lance le script directement (python generate_data.py), \n",
    "# mais qui ne sera pas execute si on l'importe dans un autre script (import generate_data).\n",
    "# Remarque : np.savetxt permet de sauvegarder les donnees dans un fichier texte au format .csv .\n",
    "def main():\n",
    "    x,y = generate_data()\n",
    "    np.savetxt(\"generated.csv\", np.column_stack((x,y))) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez maintenant votre propre module `simu_data.py` qui vous permet de générer les données de manière indépendante à leur utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Utilisation de ce module </h2>\n",
    "\n",
    "Pour utiliser ce script en tant que module, créez un fichier **`run.py`** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named simu_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-29ad9aeb38cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msimu_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named simu_data"
     ]
    }
   ],
   "source": [
    "from simu_data import generate_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    x,y = generate_data(1000, var=5)\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2ème étape : création d'un module regroupant les fonctions de la régression linéaire </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nous allons maintenant **créer un nouveau dossier** que vous allez appeler **`regression`**. Dans ce dossier, nous allons définir un nouveau module en créant le fichier **̀`linear_regression.py`**\n",
    "\n",
    "**Important !** Pensez à créer le fichier (vide) **`__init__.py`**.\n",
    "\n",
    "Dans le fichier `linear_regression.py`, nous allons créer une classe **`Linear()`** et définir dans cette classe les différentes fonctions que nous avons utilisé dans le cours \"Regression_2_Moindre_Carre_Optimisation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, x, y):\n",
    "        if (type(x) is not np.ndarray) and (type(y) is not np.ndarray):\n",
    "            raise ValueError(\"Inputs must be numpy arrays\")\n",
    "        self.x_local = x \n",
    "        self.y_local = y\n",
    "    \n",
    "    def linear_hypothesis(self, x, theta=(0,1)):\n",
    "        \"\"\" Linear function f(x)=a*x+b\n",
    "        \n",
    "        Args:\n",
    "            x (numpy.array()) : vector used to generate the output\n",
    "            theta (tuple of size 2) : b=params[0] and a=params[1]\n",
    "        \n",
    "        Returns:\n",
    "            numpy.array()\n",
    "        \"\"\"\n",
    "        a, b = theta[1], theta[0]\n",
    "        return b+a*x\n",
    "    \n",
    "    def cost(self, x, y, func, func_args):\n",
    "        \"\"\" Cost function associated with (x,y) couple and function to fit\n",
    "        \n",
    "        Args:\n",
    "            x : feature vector \n",
    "            y : explained variable\n",
    "            func : target function\n",
    "            func_args : arguments of function\n",
    "        \n",
    "        Returns:\n",
    "            scalar value of cost\n",
    "        \"\"\"\n",
    "        return 1./len(x)*sum(np.square(y-func(x,func_args)))\n",
    "    \n",
    "    def params_search(self, x, y):\n",
    "        \"\"\" Estimation des parametres : scan systematique.\n",
    "        \n",
    "        Args : x : feature vector \n",
    "               y : explained variable\n",
    "        \n",
    "        Returns:\n",
    "            Parametres optimaux de la fonction linear_hypothesis\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        params = []\n",
    "        for p0 in np.linspace(0,10):\n",
    "            for p1 in np.linspace(0,10):\n",
    "                p = (p0,p1)\n",
    "                c = self.cost(x, y, self.linear_hypothesis, p)\n",
    "                errors.append(c)\n",
    "                params.append(p)\n",
    "        return params[errors.index(min(errors))]\n",
    "    \n",
    "    def gradient_descent(self, x, y, theta=None, alpha=0.001, iterations=10000):\n",
    "        \"\"\" Estimation des parametres : descente de gradient.\n",
    "        \n",
    "        Args : x : feature vector \n",
    "               y : explained variable\n",
    "               theta : starting parameters\n",
    "               alpha : step\n",
    "               iterations : iteration number\n",
    "        \n",
    "        Returns:\n",
    "            Parametres optimaux de la fonction linear_hypothesis\n",
    "        \"\"\"\n",
    "        if theta is None:\n",
    "            theta = (5,10) \n",
    "\n",
    "        theta = list(theta)\n",
    "        N=len(y)\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            theta[0] = theta[0]-(alpha/N)*sum(self.linear_hypothesis(x,theta)-y)\n",
    "            theta[1] = theta[1]-(alpha/N)*(self.linear_hypothesis(x,theta)-y).dot(x)\n",
    "\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que l'on a regroupé les fonction, on veut les utiliser pour ajuster (*to fit* en anglais) les paramètres aux données. Toujours dans la classe, définissons maintenant la fonction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def fit(self, optimisation=None):\n",
    "        \"\"\" Fonction retournant les parametres estimes a l'aide de la methode des moindres carres.\n",
    "            \n",
    "            Args: \n",
    "                optimisation : doit etre scan_systematique ou descente_gradient\n",
    "        \"\"\"\n",
    "        if optimisation == \"scan_systematique\":\n",
    "            return self.params_search(self.x_local, self.y_local)\n",
    "        elif optimisation == \"descente_gradient\":\n",
    "            return self.gradient_descent(self.x_local, self.y_local, (5,10), alpha=0.01, iterations=5000)\n",
    "        else:\n",
    "            raise ValueError(\"The parameter optimisation must be 'scan_systematique' or 'descente_gradient'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tant qu'à faire, on peut également en profiter pour créer 2 fonctions permettant pour l'une d'afficher les données, et pour l'autre d'afficher la droite f(x)=a\\*x+b à partir de `self.linear_hypothesis(self.x_local, parameters)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def plot_data(self, show=False):\n",
    "        \"\"\" Graphe : points de donnees x en fonction de y. \n",
    "            \n",
    "        Args :\n",
    "            show : affichage optionnel\n",
    "        \"\"\"\n",
    "        plt.scatter(self.x_local,self.y_local)\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title('')\n",
    "        if show : \n",
    "            plt.show()\n",
    "\n",
    "    def plot_fit(self, parameters, legende, color='b', show=False):\n",
    "        \"\"\" Graphe : droite de la fonction lineaire f(x)=a*x+b .\n",
    "        \n",
    "        Args :\n",
    "            parameters : parametres de la droite (b=params[0] and a=params[1])\n",
    "            legende : donne une legende a la droite\n",
    "            color : change la couleur de la droite => 'b'         blue\n",
    "                                                      'g'         green\n",
    "                                                      'r'         red\n",
    "                                                      'c'         cyan\n",
    "                                                      'm'         magenta\n",
    "                                                      'y'         yellow\n",
    "                                                      'k'         black\n",
    "                                                      'w'         white\n",
    "            show : affichage optionnel\n",
    "        \"\"\"\n",
    "        plt.plot(self.x_local, self.linear_hypothesis(self.x_local, parameters), color, label=legende)\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.legend()\n",
    "        plt.title('')\n",
    "        if show : \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3ème étape : utiliser ces nouveaux modules </h2>\n",
    "\n",
    "Maintenant que nous avons défini nos nouveaux modules à l'aide de fonctions et de classes, nous devons les utiliser. Remontez dans le **dossier `POO/`** et ouvrez à nouveau le fichier **`run.py`**. \n",
    "\n",
    "On peut maintenant importer notre nouveau module **`regression`** et son sous-module **`linear_regression`** de telle manière : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from regression import linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : on pourrait également importer directement la classe `Linear` d'une de ces façons :\n",
    "\n",
    "`from regression import linear_regression.Linear as Linear` <br>\n",
    "ou <br>\n",
    "`from regression.linear_regression import Linear`\n",
    "\n",
    "Aide pour écrire le code dans `run.py` :\n",
    "\n",
    "1. Déclarez la classe `Linear` (comme vu dans Introduction_Python_2).\n",
    "1. Utilisez ses fonctions afin de déterminer les meilleurs paramètres ajustant les données avec l'option \"scan_systematique\" puis avec l'option \"descente_gradient\" de la fonction `fit`.\n",
    "1. Affichez sur un plot les points de données (fonction `plot_data()` de la classe `Linear`) ainsi que 2 droites avec comme coefficients les paramètres trouvés au point 2. (fonction `plot_fit()` de la classe `Linear`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from simu_data import generate_data\n",
    "from regression import linear_regression\n",
    "\n",
    "# Autres manières d'importer directement la classe Linear :\n",
    "#from regression import linear_regression.Linear as Linear\n",
    "# ou\n",
    "#from regression.linear_regression import Linear\n",
    "\n",
    "def main():\n",
    "    x,y = generate_data(1000, var=5)\n",
    "    \n",
    "    l = linear_regression.Linear(x,y)\n",
    "    l.plot_data()\n",
    "    params_scan = l.fit(optimisation=\"scan_systematique\")\n",
    "    print \"Parametres optimisant les moindres carres, via un scan :\", params_scan\n",
    "    l.plot_fit(params_scan, legende=\"Params scan systematique\", color=\"g\")\n",
    "    \n",
    "    params_gd = l.fit(optimisation=\"descente_gradient\")\n",
    "    print \"Parametres optimisant les moindres carres, via la descente de gradient :\", params_gd\n",
    "    l.plot_fit(params_gd, legende=\"Params descente de gradient\", color=\"r\", show=True)\n",
    "    \n",
    "    # Autre maniere d'utiliser la classe :\n",
    "    #plt.plot(l.x_local, l.linear_hypothesis(l.x_local, theta = params_gd))\n",
    "    #plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
